{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 571 - Supervised Learning I\n",
    "\n",
    "# Lab 2: Preprocessing and building a simple ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Submission instructions](#si)\n",
    "- [Introduction](#in)\n",
    "- [Exercise 1: Introducing the dataset](#1)\n",
    "- [Exercise 2: Exploratory data analysis (EDA)](#2)\n",
    "- [Exercise 3: Preprocessing and pipelines](#3)\n",
    "- [Exercise 4: Building models](#4)\n",
    "- [Exercise 5: Evaluating on the test set](#5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    normalize,\n",
    "    scale,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "rubric={mechanics:5}\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. \n",
    "\n",
    "To correctly submit this assignment follow the instructions below:\n",
    "\n",
    "- Push your assignment to your GitHub repository. \n",
    "- Add a link to your GitHub repository here: LINK TO YOUR GITHUB REPO \n",
    "- Upload an HTML render of your assignment to Canvas. The last cell of this notebook will help you do that.\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "\n",
    "[Here](https://github.com/UBC-MDS/public/tree/master/rubric) you will find the description of each rubric used in MDS.\n",
    "\n",
    "**NOTE: The data you download for use in this lab SHOULD NOT BE PUSHED TO YOUR REPOSITORY. You might be penalised for pushing datasets to your repository. I have seeded the repository with `.gitignore` and hoping that it won't let you push CSVs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3247a4b883a670c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "<hr>\n",
    "\n",
    "A crucial step when using machine learning algorithms on real-world datasets is preprocessing. This lab will give you some practice to build a preliminary supervised machine learning pipeline on a real-world dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Introducing the dataset <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "\n",
    "In this lab you will be working on a sample of [the adult census dataset](https://www.kaggle.com/uciml/adult-census-income#). Download the CSV and save it as `adult.csv` locally in the lab folder. The repository is seeded with `.gitignore *.csv`. So you won't be able to push the CSV in your repository. \n",
    "\n",
    "This is a classification dataset and the classification task is to predict whether income exceeds 50K per year or not based on the census data. You can find more information on the dataset and features [here](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "The starter code below loads the data CSV (assuming that it is saved as `adult.csv` in this folder). \n",
    "\n",
    "*Note that many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "\n",
    "# For the purpose of this lab, I am undersampling the dataset so that the labels are balanced.\n",
    "# We'll learn about dealing with unbalanced data in DSCI 573.\n",
    "adult_df_large = pd.read_csv(\"adult.csv\")\n",
    "g50k = adult_df_large[adult_df_large[\"income\"] == \">50K\"]\n",
    "leq50k_sample = adult_df_large[adult_df_large[\"income\"] == \"<=50K\"].sample(\n",
    "    g50k.shape[0]\n",
    ")\n",
    "census_df = pd.concat([g50k, leq50k_sample])\n",
    "census_df.shape\n",
    "\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data splitting \n",
    "rubric={accuracy:2}\n",
    "\n",
    "In order to avoid violation of the golden rule, the first step before we do anything is splitting the data. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into `train_df` (80%) and `test_df` (20%). Keep the target column (`income`) in the splits so that we can use it in EDA. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 2: Exploratory data analysis (EDA) <a name=\"2\"></a> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine our `train_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "\n",
    "train_df.sort_index().head()\n",
    "\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some missing values represented with a \"?\". Probably these were the questions not answered by some people during the census.  Usually `.describe()` or `.info()` methods would give you information on missing values. But here, they won't pick \"?\" as missing values as they are encoded as strings instead of an actual NaN in Python. So let's replace them with `np.NaN` before we carry out EDA. If you do not do it, you'll encounter an error later on when you try to pass this data to a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "\n",
    "train_df_nan = train_df.replace(\"?\", np.NaN)\n",
    "test_df_nan = test_df.replace(\"?\", np.NaN)\n",
    "\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Numeric vs. categorical features\n",
    "rubric={reasoning:5}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify numeric and categorical features and create lists for each of them. \n",
    "2. Are there any features which are neither numeric nor categorical in this dataset? If yes, create a separate list for those features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STATER_CODE\n",
    "\n",
    "# Fill in the lists below.\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "remainder_features = []\n",
    "\n",
    "### END STATER_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualizing features\n",
    "rubric={viz:4,reasoning:2}\n",
    "\n",
    "**Your tasks**\n",
    "1. Use `train_df_nan.info()` method to describe information of each feature and `train_df_nan.describe()` using the `include=\"all\"` argument to show summary statistics of each feature. \n",
    "2. Visualize the histograms of numeric features using either `altair` or pandas plotting. \n",
    "3. Which features seem relevant for the given prediction task? \n",
    "\n",
    "You don't have to but you are welcome to use `pandas_profiling` for more elaborate visualization and EDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Separating feature vectors and targets  \n",
    "rubric={accuracy:2,reasoning:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create `X_train`, `y_train`, `X_test`, `y_test` from `train_df_nan` and `test_df_nan`. \n",
    "2. At this point, if you train [`sklearn`'s `SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model on `X_train` and `y_train` would it work? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Preprocessing <a name=\"3\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you'll be wrangling the dataset so that it's suitable to be used with `scikit-learn` classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Identifying transformations that need to be applied\n",
    "rubric={reasoning:7}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify the columns on which transformations need to be applied and tell us what transformation you would apply in what order by filling in the table below. Example transformations are shown for the feature `age` in the table.  \n",
    "2. Are there any columns where no transformations need to be applied? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN STARTED CODE\n",
    "| Feature | Transformation |\n",
    "| --- | ----------- |\n",
    "| age | imputation, scaling |\n",
    "| workclass |  |\n",
    "| fnlwgt |  |\n",
    "| education |  |\n",
    "| education.num |  |\n",
    "| marital.status |  |\n",
    "| occupation |  |\n",
    "| relationship |  |\n",
    "| race |  |\n",
    "| sex |  |\n",
    "| capital.gain |  |\n",
    "| capital.loss |  |\n",
    "| hours.per.week |  |\n",
    "| native.country |  |\n",
    "\n",
    "### END STARTED CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2 Imputing missing values **without** `sklearn.pipeline.Pipeline`\n",
    "rubric={accuracy:5,reasoning:2}\n",
    "\n",
    "In this exercise you'll be imputing missing values **without using `scikit-learn` pipelines**. The goal here is two-fold. First, to understand what happens under the hood when you use `scikit-learn` `Pipelines`, and second, to convince yourself why it's a good idea to use pipelines.  \n",
    "\n",
    "**Your tasks:**\n",
    "1. For numeric features, use [`scikit-learn`'s `SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) to impute `NaN` values with `strategy=\"median\"`. Remember to apply the transformations on both the train and test splits.  \n",
    "2. For categorical features, use [`scikit-learn`'s `SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) to impute `NaN` values by a constant string \"missing\". Remember to apply the transformations on both the train and test splits.\n",
    "3. Show train split of categorical features in a dataframe after transforming the missing values. Do you see imputed missing values in the dataframe?  \n",
    "4. When using the `SimpleImputer` transformer on the numeric columns, is there any problem with calling `fit_transform` on the test split? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 One-hot encoding **without** `sklearn.pipeline.Pipeline`\n",
    "rubric={accuracy:8,reasoning:4}     \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Apply one-hot encoding to the categorical features of imputed `X_train` and `X_test` from 3.2 using [`scikit-learn`'s `OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and show the new columns created using the `categories_` attribute of the `OneHotEncoder` object.\n",
    "2. Create preprocessed train and test splits, `X_train_pp` and `X_test_pp`, by horizontally stacking transformed numeric columns from 3.2 and transformed categorical columns with imputation and OHE applied. \n",
    "3. What's the shape of `X_train_pp` and `X_test_pp`?\n",
    "4. Carry out cross validation using `cross_validate` on the preprocessed `X_train_pp` and `y_train` using the [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier) with default parameters. \n",
    "5. Are we violating the golden rule when we call `cross_validate` in 4.? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Using `sklearn.pipeline.Pipeline`\n",
    "rubric={accuracy:8,reasoning:2}\n",
    "\n",
    "As noted in 3.2 and 3.3, when we want to apply a series of transformations, the code becomes unwieldy quite quickly. We can do this much more elegantly using [`scikit-learn` pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).   \n",
    "\n",
    "Let's carry out preprocessing using pipelines now. Note that you can define pipelines in two ways: by using [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and providing named steps or by using [`make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline) which allows for simplified pipeline construction. In the latter case, the names of the steps will be set to the lowercase of their types automatically. You may use the method of your choice.  \n",
    "\n",
    "\n",
    "1. Define a `Pipeline` for numerical features with two steps: \n",
    "    - [`SimpleImputer()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) with `strategy = \"median\"` \n",
    "    - [`StandardScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "2. Define a `Pipeline` for categorical features with two steps: \n",
    "    - [`SimpleImputer()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) with `strategy = \"constant\"`\n",
    "    - [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) with `handle_unknown=\"ignore\"`\n",
    "\n",
    "3. Define a [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) called `preprocessor` for the numerical, categorical, and remainder features.\n",
    "4. Fit the `preprocessor` on `X_train` and `y_train`.\n",
    "5. Examine the new features created by the `OneHotEncoder`. How many new features are created for the categorical feature `marital.status`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 4: Building models <a name=\"4\"></a>\n",
    "<hr>\n",
    "\n",
    "Now that we have preprocessed features, we are ready to build models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "\n",
    "# Lets create an empty dictionary to store all the results\n",
    "results_dict = {}\n",
    "\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "\n",
    "# You may use or adapt this function to keep your results organized\n",
    "def store_cross_val_results(model_name, scores, results_dict):\n",
    "    \"\"\"\n",
    "    Stores mean scores from cross_validate in results_dict for\n",
    "    the given model model_name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name :\n",
    "        scikit-learn classification model\n",
    "    scores : dict\n",
    "        object return by `cross_validate`\n",
    "    results_dict: dict\n",
    "        dictionary to store results\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    results_dict[model_name] = {\n",
    "        \"mean_train_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"train_score\"])),\n",
    "        \"mean_validation_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"test_score\"])),\n",
    "        \"mean_fit_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"fit_time\"])),\n",
    "        \"mean_score_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"score_time\"])),\n",
    "        \"std_train_score\": \"{:0.4f}\".format(scores[\"train_score\"].std()),\n",
    "        \"std_test_score\": \"{:0.4f}\".format(scores[\"test_score\"].std()),\n",
    "    }\n",
    "\n",
    "\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1 Building a baseline model \n",
    "rubric={accuracy:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Define a pipeline with two steps: preprocessor from 3.4 and `scikit-learn`'s `DummyClassifier` with `strategy=\"prior\"` as your classifier.  \n",
    "2. Carry out 5-fold cross validation with the pipeline. Store the results in `results_dict` above. (You may use the function above `store_cross_val_results` to store the results.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2 Trying different classifiers\n",
    "rubric={accuracy:6,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. For each of the models in the starter code below: \n",
    "    - Define a pipeline with two steps: preprocessor from 3.4 and the model as your classifier.  \n",
    "    - Carry out 5-fold cross validation with the pipeline using `cross_validate`.\n",
    "    - Store the results in `results_dict`. (You may use the function above `store_cross_val_results` to store the results.) \n",
    "2. Display all the results so far as a dataframe. \n",
    "3. Compare the train and validation accuracies and `fit` and `score` times in each case. How do the the validation accuracies compare to the baseline model from 4.1? Which model has the best validation accuracy? Which model is the fastest one?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE \n",
    "\n",
    "models = {\n",
    "    \"decision tree\": DecisionTreeClassifier(),\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"RBF SVM\": SVC(),\n",
    "}\n",
    "\n",
    "### END STARTER CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 4.3 Exploring importance of scaling\n",
    "rubric={reasoning:1}\n",
    "\n",
    "In this exercise you'll examine whether scaling helps in case of KNN and RBF SVM. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a column transformer without the `StandardScaler` step for `numeric_features`. \n",
    "2. Repeat the steps in 4.2 with this new column transformer. \n",
    "3. Compare the results with scaled numeric features with unscaled numeric features. Is scaling necessary for decision trees? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Hyperparameter optimization\n",
    "rubric={accuracy:4,reasoning:2}\n",
    "\n",
    "In this exercise, you'll carry out hyperparameter optimization for the hyperparameter `C` of SVC RBF classifier. In practice you'll carry out hyperparameter optimization for all different hyperparameters for the most promising classifiers. For the purpose of this assignment, we'll only do it for our best performing `SVC` classifier with one hyperparameter, `C`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. For each `C` value in the `param_grid` in the starter code below: \n",
    "    - Create a pipeline object with two steps: preprocessor from 3.4 and SVC classifier with the value of `C`.\n",
    "    - Carry out cross-validation using `cross_validate` and store results in the `results_dict` using the function `store_cross_val_results`. You may pass the `model_name` as `SVC` + the current `C` value. \n",
    "2. Which hyperparameter value seems to be performing the best? Is it different than the default value for the hyperparameter used by `scikit-learn`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "\n",
    "param_grid = {\"C\": np.logspace(-3, 2, 6)}\n",
    "\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (Optional) 4.5 Hyperparameter optimization of multiple parameters\n",
    "rubric={reasoning:1}\n",
    "\n",
    "In the previous exercise we carried out hyperparameter optimization of only one hyperparameter. But as we saw in class `SVC` has two important hyperparameters: `C` and `gamma` which may interact with each other and we need to optimize them both simultaneously.  \n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out hyperparameter optimization of `C` and `gamma` simultaneously for the param grid of your choice. \n",
    "2. Do you get a different value for `C` than in 4.4? \n",
    "\n",
    "**Note: The material required to answer this question is not covered this week. This block I am trying something new. In some of the labs I will be including an optional question which leads to the material in the upcoming week. It's a low-risk question and is worth only one point. The evaluation of this question is going to be pretty lenient. The intention here is not to get the perfect answer from you but to get you thinking about the upcoming material.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 5: Evaluating on the test set <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "Now that we have a best performing model, it's time to assess our model on the set aside test set. In this exercise you'll examine whether the results you obtained using cross-validation on the train set are consistent with the results on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Scoring on the unseen test set \n",
    "rubric={accuracy:4,reasoning:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Report the results on `X_test` for all classifiers. Pick the best hyperparameter from 4.4 for the SVC RBF classifier. \n",
    "2. Compare and discuss the train, validation, and test results of all classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission to Canvas\n",
    "\n",
    "**PLEASE READ: When you are ready to submit your assignment do the following:**\n",
    "\n",
    "- Run all cells in your notebook to make sure there are no errors by doing Kernel -->  Restart Kernel and Run All Cells...\n",
    "- If you are using the \"571\" `conda` environment, make sure to select it before running all cells. \n",
    "- Convert your notebook to .html format using the `convert_notebook()` function below or by File -> Export Notebook As... -> Export Notebook to HTML\n",
    "- Run the code `submit()` below to go through an interactive submission process to Canvas.\n",
    "After submission, be sure to do a final push of all your work to GitHub (including the rendered html file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from canvasutils.submit import convert_notebook, submit\n",
    "\n",
    "# convert_notebook(\"lab1.ipynb\", \"html\")  # uncomment and run when you want to try convert your notebook (or you can convert manually from the File menu)\n",
    "# submit(course_code=53670, token=False)  # uncomment and run when ready to submit to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations on finishing the lab! Now you are ready to build a simple ML pipeline on real-world datasets! Well done :clap:! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:571]",
   "language": "python",
   "name": "conda-env-571-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
