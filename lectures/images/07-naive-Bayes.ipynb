{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSCI 571: Supervised Machine Learning I \n",
    "\n",
    "## Lecture 7: Naive Bayes\n",
    "\n",
    "UBC Master of Data Science program, 2020-21\n",
    "\n",
    "Instructor: Varada Kolhatkar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# And import the libraries\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "%pylab inline\n",
    "# pip install git+git://github.com/mgelbart/plot-classifier.git\n",
    "from plot_classifier import plot_classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfTransformer,\n",
    "    TfidfVectorizer,\n",
    ")\n",
    "\n",
    "# train test split and cross validation\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Lecture learning objectives\n",
    "\n",
    "From this lecture, you will be able to \n",
    "\n",
    "- explain how the naive Bayes predicts targets\n",
    "- use `scikit-learn`'s implementation of naive Bayes \n",
    "- explain the naive assumption of naive Bayes\n",
    "- explain `predict_proba` for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Example: spam/non spam\n",
    "Last week in your lab you worked on spam classification using `SVC` classifier. \n",
    "\n",
    "$X = \\begin{bmatrix}\\text{\"URGENT!! You have been selected to receive a £900 prize reward!\",}\\\\ \\text{\"Lol your always so convincing.\"}\\\\ \\text{\"Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now!\"}\\\\ \\end{bmatrix}$ and $y = \\begin{bmatrix}\\text{spam} \\\\ \\text{non spam} \\\\ \\text{spam} \\end{bmatrix}$\n",
    "\n",
    "\n",
    "ML algorithms we have seen so far prefer fixed length numeric input that looks like this: \n",
    "\n",
    "$X = \\begin{bmatrix}1.0 & 4.0 & \\ldots & & 3.0\\\\ 0.0 & 2.0 & \\ldots & & 6.0\\\\ 1.0 & 0.0 & \\ldots & & 0.0\\\\ \\end{bmatrix}$ and $y = \\begin{bmatrix}\\text{spam} \\\\ \\text{non spam} \\\\ \\text{spam} \\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `CountVectorizer` to get bag-of-words (BOW) representation\n",
    "\n",
    "- So we used `CountVectorizer` to convert text data into feature vectors where\n",
    "    - each feature is a unique word in the text  \n",
    "    - each feature value represents the frequency or presence/absence of the word in the given message         \n",
    "    \n",
    "<center>\n",
    "<img src='./images/bag-of-words.png' width=\"800\">\n",
    "</center>\n",
    "\n",
    "[Source](https://web.stanford.edu/~jurafsky/slp3/4.pdf)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes\n",
    "\n",
    "- For years, best spam filtering methods used naive Bayes.\n",
    "- Our first probabilistic classifier where we think of learning as a problem of statistical inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Naive Bayes classifier\n",
    "\n",
    "\n",
    "Before understanding the theory, let's try `scikit-learn`'s implementation of Naive Bayes on Kaggle's [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sms_df = pd.read_csv(\"data/spam.csv\", encoding=\"latin-1\")\n",
    "sms_df = sms_df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "sms_df = sms_df.rename(columns={\"v1\": \"target\", \"v2\": \"sms\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>ham</td>\n",
       "      <td>It took Mr owl 3 licks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well there's a pattern emerging of my friends telling me to drive up and come smoke with them and then telling me that I'm a weed fiend/make them smoke too much/impede their doing other things so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i thought so. Thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! Your mobile number *************** WON a å£2000 Bonus Caller prize on 10/06/03! This is the 2nd attempt to reach you! Call 09066368753 ASAP! Box 97N7QP, 150ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aiyah sorry lor... I watch tv watch until i forgot 2 check my phone.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  \\\n",
       "385     ham   \n",
       "4003    ham   \n",
       "1283    ham   \n",
       "2327   spam   \n",
       "1103    ham   \n",
       "\n",
       "                                                                                                                                                                                                          sms  \n",
       "385                                                                                                                                                                                    It took Mr owl 3 licks  \n",
       "4003  Well there's a pattern emerging of my friends telling me to drive up and come smoke with them and then telling me that I'm a weed fiend/make them smoke too much/impede their doing other things so ...  \n",
       "1283                                                                                                                                                                                Yes i thought so. Thanks.  \n",
       "2327                                  URGENT! Your mobile number *************** WON a å£2000 Bonus Caller prize on 10/06/03! This is the 2nd attempt to reach you! Call 09066368753 ASAP! Box 97N7QP, 150ppm  \n",
       "1103                                                                                                                                     Aiyah sorry lor... I watch tv watch until i forgot 2 check my phone.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(sms_df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df[\"sms\"], train_df[\"target\"]\n",
    "X_test, y_test = test_df[\"sms\"], test_df[\"target\"]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def store_cross_val_results(model_name, scores, results_dict):\n",
    "    \"\"\"\n",
    "    Stores mean scores from cross_validate in results_dict for\n",
    "    the given model model_name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name :\n",
    "        scikit-learn classification model\n",
    "    scores : dict\n",
    "        object return by `cross_validate`\n",
    "    results_dict: dict\n",
    "        dictionary to store results\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    results_dict[model_name] = {\n",
    "        \"mean_train_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"train_score\"])),\n",
    "        \"mean_valid_accuracy\": \"{:0.4f}\".format(np.mean(scores[\"test_score\"])),\n",
    "        \"mean_fit_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"fit_time\"])),\n",
    "        \"mean_score_time (s)\": \"{:0.4f}\".format(np.mean(scores[\"score_time\"])),\n",
    "        \"std_train_score\": \"{:0.4f}\".format(scores[\"train_score\"].std()),\n",
    "        \"std_valid_score\": \"{:0.4f}\".format(scores[\"test_score\"].std()),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SVC classifier for spam detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "pipe_svc= make_pipeline(CountVectorizer(), SVC())\n",
    "scores = cross_validate(pipe_svc, X_train, y_train, return_train_score=True)\n",
    "store_cross_val_results('SVC', scores, results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time (s)</th>\n",
       "      <th>mean_score_time (s)</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_valid_accuracy</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>std_valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time (s) mean_score_time (s) mean_train_accuracy  \\\n",
       "SVC            0.5274              0.1128              0.9950   \n",
       "\n",
       "    mean_valid_accuracy std_train_score std_valid_score  \n",
       "SVC              0.9785          0.0005          0.0048  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes classifier \n",
    "\n",
    "- Let's try it with Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipe_nb = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "scores = cross_validate(pipe_nb, X_train, y_train, return_train_score=True)\n",
    "store_cross_val_results('Naive Bayes', scores, results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>mean_valid_accuracy</th>\n",
       "      <th>mean_fit_time (s)</th>\n",
       "      <th>mean_score_time (s)</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>std_valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean_train_accuracy mean_valid_accuracy mean_fit_time (s)  \\\n",
       "SVC                      0.9950              0.9785            0.5274   \n",
       "Naive Bayes              0.9935              0.9859            0.0427   \n",
       "\n",
       "            mean_score_time (s) std_train_score std_valid_score  \n",
       "SVC                      0.1128          0.0005          0.0048  \n",
       "Naive Bayes              0.0090          0.0007          0.0026  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The validation scores are a bit better on this particular dataset.\n",
    "- Way more faster than SVC classifier!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes `predict`\n",
    "\n",
    "- Given a new message, we want to predict whether it's spam or non spam (ham).\n",
    "- Example: Predict whether the following message is spam or non spam (ham). \n",
    "> \"URGENT! Free!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_nb = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_nb.fit(X_train, y_train)\n",
    "deploy_test = [\"URGENT! Free!!\", \"Let's enjoy the last week of block 2!\"]\n",
    "pipe_nb.predict(deploy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probabilistic classifiers: `predict`\n",
    "\n",
    "- What's it's doing under the hood? \n",
    "- Let's look at an example with a toy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X = [\n",
    "    \"URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!\",\n",
    "    \"Lol you are always so convincing.\",\n",
    "    \"Block 2 has interesting courses.\",\n",
    "    \"URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!\",\n",
    "    \"Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!\",\n",
    "    \"Block 2 has been interesting so far.\",\n",
    "]\n",
    "y = [\"spam\", \"non spam\", \"non spam\", \"spam\", \"spam\", \"non spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pipe_nb_toy = make_pipeline(CountVectorizer(max_features = 4, stop_words='english'), MultinomialNB())\n",
    "pipe_nb_toy.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has interesting courses.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has been interesting so far.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              block  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      0   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  1   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       0   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              1   \n",
       "\n",
       "                                                                                                              free  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                     0   \n",
       "Lol you are always so convincing.                                                                                0   \n",
       "Block 2 has interesting courses.                                                                                 0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                      1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!     1   \n",
       "Block 2 has been interesting so far.                                                                             0   \n",
       "\n",
       "                                                                                                              prize  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      1   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              0   \n",
       "\n",
       "                                                                                                              urgent  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                       1   \n",
       "Lol you are always so convincing.                                                                                  0   \n",
       "Block 2 has interesting courses.                                                                                   0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                        1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!       0   \n",
       "Block 2 has been interesting so far.                                                                               0   \n",
       "\n",
       "                                                                                                                target  \n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      spam  \n",
       "Lol you are always so convincing.                                                                             non spam  \n",
       "Block 2 has interesting courses.                                                                              non spam  \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       spam  \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      spam  \n",
       "Block 2 has been interesting so far.                                                                          non spam  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pipe_nb_toy['countvectorizer'].transform(X)\n",
    "train_bow_df = pd.DataFrame(data.toarray(), columns=pipe_nb_toy['countvectorizer'].get_feature_names(), index=X)\n",
    "train_bow_df['target'] = y\n",
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose we are given text messages in `deploy_test` and we want to find the targets for these examples, how do we do it using naive Bayes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>urgent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT! Free!!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like block 2.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 block  free  prize  urgent\n",
       "URGENT! Free!!       0     1      0       1\n",
       "I like block 2.      1     0      0       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_test = [\"URGENT! Free!!\", \"I like block 2.\"]\n",
    "data = pipe_nb_toy['countvectorizer'].transform(deploy_test).toarray()\n",
    "bow_df = pd.DataFrame(data, columns=pipe_nb_toy['countvectorizer'].get_feature_names(), index=deploy_test)\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes prediction idea\n",
    "\n",
    "Suppose we want to predict whether the following message is \"spam\" or \"non spam\".\n",
    "> \"URGENT! Free!!\"\n",
    "\n",
    "Representation of the message: `[0, 1, 0, 1]`\n",
    "\n",
    "To predict the correct class, naive Bayes calculates the following probabilities\n",
    "\n",
    "- $P(\\text{spam} \\mid \\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent=1})$ \n",
    "- $P(\\text{non spam} \\mid  \\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent=1})$\n",
    "- Picks the label with higher probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applying Bayes' theorem \n",
    "\n",
    "Uses Bayes' theorem for to calculate probabilities:\n",
    "\n",
    "$$P(A \\mid B) = \\frac{P(B \\mid A) \\times P(A)}{P(B)}$$\n",
    "\n",
    "$$P(\\text{spam} \\mid \\text{message})= \\frac{P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{spam}) \\times P(\\text{spam})}{P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent=1})}$$\n",
    "\n",
    "$$P(\\text{non spam} \\mid \\text{message}) = \\frac{P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{non spam}) \\times P( \\text{non spam})}{P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent=1})}$$\n",
    "\n",
    "- $P(\\text{message})$: marginal probability that a message has the given set of words \n",
    "    - Hard to calculate but can be ignored in our scenario as it occurs as the denominator for both $P(\\text{spam} \\mid \\text{message})$ and $P(\\text{non spam} \\mid \\text{message})$\n",
    "    - So we skip the denominator in both cases. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's focus on $P(\\text{spam} \\mid \\text{message})$\n",
    "$$P(\\text{spam} \\mid \\text{message}) \\propto P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{spam}) \\times P(\\text{spam})$$\n",
    "\n",
    "- To calculate $P(\\text{spam} \\mid \\text{message})$, we need:  \n",
    "    - $P(\\text{spam})$: marginal probability that a message is spam\n",
    "    - $P(\\text{message}\\mid\\text{spam})$: conditional probability that message has words $w_1, w_2, \\dots, w_d$, given that it is spam.\n",
    "        - Hard to calculate because would require huge numbers of parameters and impossibly large training sets. But we need it. \n",
    "        - with $d$ binary features, how many possible \"text messages\" are there?\n",
    "        - we cannot possibly have access to all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes' approximation to calculate $P(\\text{message}|\\text{spam})$\n",
    "\n",
    "- A common assmption is **naive Bayes** assumption, which states that **features are independent, conditioned on the target**. \n",
    "    - Example: In our spam classification example, **once you know that a message is spam**, the probability that the word \"urgent\" appears is independent of whether \"free\" also appeared. \n",
    "    \n",
    "- We can write this mathematically as \n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "& P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{spam}) \\\\\n",
    "&\\approx P(\\text{block} = 0 \\mid \\text{spam}) \\times P(\\text{free} = 1 \\mid \\text{spam}) \\times P(\\text{prize} = 0 \\mid \\text{spam}) \\times P(\\text{urgent} = 1 \\mid \\text{spam})\n",
    "\\end{split}\n",
    "\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes' approximation\n",
    "\n",
    "- In general, \n",
    "$$P(\\text{message} \\mid \\text{spam}) = P(w_1, w_2, . . . , w_d \\mid \\text{spam}) \\approx \\prod_{i=1}^{d}P(w_i \\mid \\text{spam})$$\n",
    "\n",
    "$$P(\\text{message} \\mid \\text{non spam}) = P(w_1, w_2, . . . , w_d \\mid \\text{non spam}) \\approx \\prod_{i=1}^{d}P(w_i \\mid \\text{non spam})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What do we need?\n",
    "\n",
    "With naive Bayes' assumption, to calculate $P(\\text{spam} \\mid \\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1)$, we need the following:  \n",
    "1. Prior probability: $P(\\text{spam})$ \n",
    "2. Conditional probabilities: \n",
    "    1. $P(\\text{block} = 0 \\mid \\text{spam})$\n",
    "    2. $P(\\text{free} = 1 \\mid \\text{spam})$\n",
    "    3. $P(\\text{prize} = 0 \\mid \\text{spam})$\n",
    "    4. $P(\\text{urgent} = 1 \\mid \\text{spam})$\n",
    "\n",
    "We use our training data to calculate these probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has interesting courses.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has been interesting so far.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              block  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      0   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  1   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       0   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              1   \n",
       "\n",
       "                                                                                                              free  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                     0   \n",
       "Lol you are always so convincing.                                                                                0   \n",
       "Block 2 has interesting courses.                                                                                 0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                      1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!     1   \n",
       "Block 2 has been interesting so far.                                                                             0   \n",
       "\n",
       "                                                                                                              prize  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      1   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              0   \n",
       "\n",
       "                                                                                                              urgent  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                       1   \n",
       "Lol you are always so convincing.                                                                                  0   \n",
       "Block 2 has interesting courses.                                                                                   0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                        1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!       0   \n",
       "Block 2 has been interesting so far.                                                                               0   \n",
       "\n",
       "                                                                                                                target  \n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      spam  \n",
       "Lol you are always so convincing.                                                                             non spam  \n",
       "Block 2 has interesting courses.                                                                              non spam  \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       spam  \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      spam  \n",
       "Block 2 has been interesting so far.                                                                          non spam  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Prior probability\n",
    "    - $P(\\text{spam}) = 3/6$\n",
    "    \n",
    "- Conditional probabilities\n",
    "    - What is $P(\\text{block} = 0 \\mid \\text{spam})$? \n",
    "        - Given target is spam, how often \"block\" = 0? $3/3$\n",
    "    - $P(\\text{free} = 1 \\mid \\text{spam}) = 2/3$ \n",
    "    - $P(\\text{prize} = 0 \\mid \\text{spam}) = 1/3$\n",
    "    - $P(\\text{urgent} = 1 \\mid \\text{spam}) = 2/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating $P(\\text{spam} \\mid \\text{message})$\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\text{spam} \\mid \\text{message}) &\\propto P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{spam}) \\times P(\\text{spam})\\\\\n",
    "&\\propto P(\\text{block} = 0 \\mid \\text{spam}) \\times P(\\text{free} = 1 \\mid \\text{spam}) \\\\\n",
    "& \\times P(\\text{prize} = 0 \\mid \\text{spam}) \\times P(\\text{urgent} = 1 \\mid \\text{spam}) \\times P(\\text{spam})\\\\\n",
    "&\\propto 3/3 \\times 2/3 \\times 1/3 \\times 2/3 \\times 3/6\\\\\n",
    "\\end{split}\n",
    "\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07407407407407407"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_prior = 3/6\n",
    "block0_spam = 3/3\n",
    "free1_spam = 2/3\n",
    "prize0_spam = 1/3\n",
    "urgent1_spam = 2/3\n",
    "spam_prior * block0_spam * free1_spam * prize0_spam * urgent1_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's calculate the estimate for 'non spam'. \n",
    "\n",
    "With naive Bayes' assumption, to calculate $P(\\text{non spam} \\mid \\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1)$, we need the following:  \n",
    "1. Prior probability: $P(\\text{non spam})$ \n",
    "2. Conditional probabilities: \n",
    "    1. $P(\\text{block} = 0 \\mid \\text{non spam})$\n",
    "    2. $P(\\text{free} = 1 \\mid \\text{non spam})$\n",
    "    3. $P(\\text{prize} = 0 \\mid \\text{non spam})$\n",
    "    4. $P(\\text{urgent} = 1 \\mid \\text{non spam})$\n",
    "\n",
    "Again we use the data to calculate these probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has interesting courses.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has been interesting so far.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              block  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      0   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  1   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       0   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              1   \n",
       "\n",
       "                                                                                                              free  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                     0   \n",
       "Lol you are always so convincing.                                                                                0   \n",
       "Block 2 has interesting courses.                                                                                 0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                      1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!     1   \n",
       "Block 2 has been interesting so far.                                                                             0   \n",
       "\n",
       "                                                                                                              prize  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      1   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              0   \n",
       "\n",
       "                                                                                                              urgent  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                       1   \n",
       "Lol you are always so convincing.                                                                                  0   \n",
       "Block 2 has interesting courses.                                                                                   0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                        1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!       0   \n",
       "Block 2 has been interesting so far.                                                                               0   \n",
       "\n",
       "                                                                                                                target  \n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      spam  \n",
       "Lol you are always so convincing.                                                                             non spam  \n",
       "Block 2 has interesting courses.                                                                              non spam  \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       spam  \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      spam  \n",
       "Block 2 has been interesting so far.                                                                          non spam  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Prior probability \n",
    "    - $P(\\text{non spam}) = 3/6$\n",
    "\n",
    "- Conditional probabilities \n",
    "    - What is $P(\\text{block} = 0 \\mid \\text{non spam})$? \n",
    "        - Given target is non spam, how often \"block\" = 0? $1/3$\n",
    "    - $P(\\text{free} = 1 \\mid \\text{non spam}) = 0/3$ \n",
    "    - $P(\\text{prize} = 0 \\mid \\text{non spam}) = 3/3$\n",
    "    - $P(\\text{urgent} = 1 \\mid \\text{non spam}) = 0/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating $P(\\text{non spam} \\mid \\text{message})$\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "P(\\text{non spam} \\mid \\text{message}) &\\propto P(\\text{block} = 0, \\text{free} = 1, \\text{prize} = 0, \\text{urgent} = 1 \\mid \\text{non spam}) \\times P(\\text{non spam})\\\\\n",
    "&\\propto P(\\text{block} = 0 \\mid \\text{non spam}) \\times P(\\text{free} = 1 \\mid \\text{non spam}) \\\\\n",
    "& \\times P(\\text{prize} = 0 \\mid \\text{non spam}) \\times P(\\text{urgent} = 1 \\mid \\text{non spam}) \\times P(\\text{non spam})\\\\\n",
    "&\\propto 1/3 \\times 0 \\times 3/3 \\times 0 \\times 1/3\\\\\n",
    "\\end{split}\n",
    "\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_spam_prior = 3/6\n",
    "block0_non_spam = 0/3\n",
    "free1_non_spam = 1/3\n",
    "prize0_non_spam = 1/3\n",
    "urgent1_non_spam = 2/3\n",
    "non_spam_prior * block0_non_spam * free1_non_spam * prize0_non_spam * urgent1_non_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes prediction\n",
    "\n",
    "Since $(\\text{spam} \\mid \\text{message})$ (0.074) is proportional to a larger number compared to $(\\text{non spam} \\mid \\text{message})$ (0), we predict $spam$! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise for you\n",
    "\n",
    "- Predict for the second example in our `deploy_test`: \"I like block 2.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Summary naive Bayes `predict`\n",
    "- Use Bayes rule to calculate the conditional probability of spam or non spam given the message. \n",
    "\n",
    "$$ P(\\text{spam} \\mid \\text{message}) = \\frac{P(\\text{message} \\mid \\text{spam}) \\times P(\\text{spam})}{P(\\text{message})} $$\n",
    "\n",
    "$$ P(\\text{non spam} \\mid \\text{message}) = \\frac{P(\\text{message} \\mid \\text{non spam}) \\times P(\\text{non spam})}{P(\\text{message})} $$\n",
    "\n",
    "\n",
    "- $P(\\text{message})$: marginal probability that a message has the given set of words \n",
    "    - Hard to calculate but can be ignored in our scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Summary naive Bayes `predict`\n",
    "$$ P(\\text{spam} \\mid \\text{message}) \\propto \\frac{P(\\text{message} \\mid\\text{spam}) \\times P(\\text{spam})}{P(\\text{message})} =  \\frac{P(w_1, w_2, \\dots, w_d \\mid \\text{spam}) \\times P(\\text{spam})}{P(w_1, w_2, \\dots, w_d)}$$\n",
    "\n",
    "- We need the following terms:  \n",
    "    - $P(\\text{spam})$: marginal probability that a message is spam\n",
    "    - $P(\\text{message}\\mid\\text{spam})$: conditional probability that message has words $w_1, w_2, \\dots, w_d$, given that it is spam.\n",
    "        - Hard to calculate but we need it. We would require huge numbers of parameters and impossibly large training sets. \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Summary naive Bayes `predict`\n",
    "\n",
    "- Estimate the following probabilities using naive Bayes' assumption \n",
    "- Predict the class with bigger value. \n",
    "\n",
    "$$ P(\\text{spam} \\mid \\text{message}) \\approx P(\\text{spam}) \\times  \\prod_{i=1}^{d}P(w_i \\mid \\text{spam})$$\n",
    "\n",
    "$$ P(\\text{spam} \\mid \\text{message}) \\approx P(\\text{non spam}) \\times  \\prod_{i=1}^{d}P(w_i \\mid \\text{non spam})$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Questions\n",
    "\n",
    "- When we ignore the marginal probability P(message) when calculating $P(\\text{spam} | \\text{message})$ or $P(\\text{spam} | \\text{message})$, are these going to be well-defined probabilites? Does it matter?  \n",
    "- Does naive Bayes assumption help us estimating P(message) as well? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. `predict_proba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is our toy pipeline's prediction? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U8')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_test = [\"URGENT! Free!!\"]\n",
    "pipe_nb_toy.predict(deploy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier `predict_proba`\n",
    "- So far we have been looking into binary predictions but often a more granular information is useful. \n",
    "- Naive Bayes classifier gives you probability estimates for each class and we can get this information using `predict_proba` method of the classifier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23584906, 0.76415094]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_nb_toy.predict_proba(deploy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier is \"76% confident\" that the class is spam! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting probabilities\n",
    "\n",
    "- We have a new and useful method, `predict_proba`.\n",
    "- `predict` returns the class with the highest probability.\n",
    "- `predict_proba` gives us the actual probability scores. \n",
    "- Looking at the probabilities can help us understand the model.\n",
    "- We can find the spam messages where our classifier is most confident and least confident. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Although decision tree, kNN, and RBF SVM are not set in a probabilistic framework, they still have `predict_proba` method to get the probability estimates.  \n",
    "\n",
    "- [`DecisionTreeClasifier.predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict_proba)\n",
    "  - Computed as fraction of that class in leaf node.\n",
    "- [`KNeighborsClassifier.predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict_proba)\n",
    "  - Computed as fraction of that class in $k$ neighbours.\n",
    "- [`MultinomialNB.predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB.predict_proba)\n",
    "  - Already computed, just need to normalize them (so they sum to 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes classifier `fit`\n",
    "\n",
    "- Calculate prior probabilities and conditional probabilities for each feature given each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recall that before we calculated \n",
    "    - $P(\\text{non spam} \\mid \\text{message}) \\propto 0$\n",
    "    - $P(\\text{spam} \\mid \\text{message}) \\propto 0.074$\n",
    "- Why don't `predict_proba` scores match with the probability scores we calculated before? \n",
    "- The scores we computed are not normalized. Remember that we ignored the denominator.\n",
    "- These ones are normalized so that they sum to 1.\n",
    "- The model is using something called \"smoothing\" to avoid the problem of zero probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23584906, 0.76415094]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_nb_toy.predict_proba(deploy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Laplace smoothing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>urgent</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lol you are always so convincing.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has interesting courses.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block 2 has been interesting so far.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              block  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      0   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  1   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       0   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              1   \n",
       "\n",
       "                                                                                                              free  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                     0   \n",
       "Lol you are always so convincing.                                                                                0   \n",
       "Block 2 has interesting courses.                                                                                 0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                      1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!     1   \n",
       "Block 2 has been interesting so far.                                                                             0   \n",
       "\n",
       "                                                                                                              prize  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      1   \n",
       "Lol you are always so convincing.                                                                                 0   \n",
       "Block 2 has interesting courses.                                                                                  0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      0   \n",
       "Block 2 has been interesting so far.                                                                              0   \n",
       "\n",
       "                                                                                                              urgent  \\\n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                       1   \n",
       "Lol you are always so convincing.                                                                                  0   \n",
       "Block 2 has interesting courses.                                                                                   0   \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                        1   \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!       0   \n",
       "Block 2 has been interesting so far.                                                                               0   \n",
       "\n",
       "                                                                                                                target  \n",
       "URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!                      spam  \n",
       "Lol you are always so convincing.                                                                             non spam  \n",
       "Block 2 has interesting courses.                                                                              non spam  \n",
       "URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!                                       spam  \n",
       "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!      spam  \n",
       "Block 2 has been interesting so far.                                                                          non spam  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Remember when we calculated $P(\\text{non spam} \\mid \\text{message})$, some of our conditional probabilities were zero. \n",
    "    - $P(\\text{free} = 1 \\mid \\text{non spam}) = 0/3$ \n",
    "    - $P(\\text{urgent} = 1 \\mid \\text{non spam}) = 0/3$\n",
    "\n",
    "- Naive Bayes naively multiplies all the feature likelihoods together, and if any of the terms is zero, it's going to void all other evidence and the probability of the class is going to be zero. \n",
    "- Sounds worrisome! \n",
    "- We have limited data and if we do not see a feature occurring with a class, it doesn't mean it would never occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A simplest solution: Laplace smoothing\n",
    "\n",
    "- The simplest way to avoid zero probabilities is to add one to all the counts\n",
    "- All the counts that used to be zero will now have a count of 1, the counts of 1 will be 2, and so on. \n",
    "- In `scikit-learn` we control it using hyperparameter `alpha` (by default `alpha=1.0`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb = make_pipeline(CountVectorizer(), MultinomialNB(alpha=1.0))\n",
    "pipe_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `alpha` hyperparameter and the fundamental tradeoff \n",
    "\n",
    "- High alpha $\\rightarrow$ underfitting\n",
    "    - means we are adding large counts to everything and so we are diluting the data\n",
    "- Low alpha $\\rightarrow$ overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_cv_score</th>\n",
       "      <th>std_cv_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.044721</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99500</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.040620</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.93625</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.009186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.87000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.87000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         alpha  mean_train_score  mean_cv_score  std_cv_score  std_train_score\n",
       "0     0.000001           1.00000          0.945      0.040000         0.000000\n",
       "1     0.000010           1.00000          0.950      0.044721         0.000000\n",
       "2     0.000100           1.00000          0.955      0.036742         0.000000\n",
       "3     0.001000           1.00000          0.955      0.036742         0.000000\n",
       "4     0.010000           1.00000          0.955      0.036742         0.000000\n",
       "5     0.100000           0.99875          0.950      0.035355         0.002500\n",
       "6     1.000000           0.99500          0.960      0.040620         0.002500\n",
       "7    10.000000           0.93625          0.870      0.010000         0.009186\n",
       "8   100.000000           0.87000          0.870      0.010000         0.002500\n",
       "9  1000.000000           0.87000          0.870      0.010000         0.002500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {\"alpha\": [], \"mean_train_score\": [], \"mean_cv_score\": [], \"std_cv_score\" : [], \"std_train_score\":[]}\n",
    "param_grid = {\"alpha\": 10.0**np.arange(-6,4)}\n",
    "\n",
    "for alpha in param_grid[\"alpha\"]:\n",
    "    pipe_nb = make_pipeline(CountVectorizer(), MultinomialNB(alpha = alpha))\n",
    "    scores = cross_validate(pipe_nb, X_train[:200], y_train[:200], return_train_score=True)\n",
    "    results_dict[\"alpha\"].append(alpha)\n",
    "    results_dict[\"mean_cv_score\"].append(np.mean(scores[\"test_score\"]))\n",
    "    results_dict[\"mean_train_score\"].append(np.mean(scores[\"train_score\"]))\n",
    "    results_dict[\"std_cv_score\"].append(scores[\"test_score\"].std())\n",
    "    results_dict[\"std_train_score\"].append(scores[\"train_score\"].std())\n",
    "\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(param_grid[\"alpha\"],results_dict[\"mean_train_score\"],label=\"train\");\n",
    "plt.semilogx(param_grid[\"alpha\"],results_dict[\"mean_cv_score\"],label=\"cv\");\n",
    "plt.legend();\n",
    "plt.xlabel('laplace smoothing (alpha)');\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Questions: True or False \n",
    "- Laplace smoothing helps us deal with unknown words, the words that we do not occur in the vocabulary of the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes with continuous features\n",
    "\n",
    "- We can use Gaussian Naive Bayes if you have continuous features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/canada_usa_cities.csv\")\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 123) # 80%-20% train test split on df\n",
    "X_train, y_train = train_df.drop(columns=[\"country\"]), train_df[\"country\"] \n",
    "X_test, y_test = test_df.drop(columns=[\"country\"]), test_df[\"country\"]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada = train_df.query('country == \"Canada\"')\n",
    "usa = train_df.query('country == \"USA\"')\n",
    "plt.scatter(canada[\"longitude\"], canada[\"latitude\"], color=\"red\", alpha=0.6)\n",
    "plt.scatter(usa[\"longitude\"], usa[\"latitude\"], color=\"blue\", alpha=0.6)\n",
    "plt.ylabel(\"latitude\")\n",
    "plt.xlabel(\"longitude\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize probabilistic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "plot_classifier(X_train, y_train, model, ax=ax, proba=True);\n",
    "\n",
    "plt.ylabel(\"latitude\");\n",
    "plt.xlabel(\"longitude\");\n",
    "plt.title(\"Naive Bayes decision boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predictions in darker colours: the model is more confident\n",
    "- Predictions in lighter colours: the model is less confident"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on multi-class problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import \n",
    "newsgroups_train = datasets.fetch_20newsgroups(subset='train')\n",
    "newsgroups_test  = datasets.fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative models\n",
    " \n",
    "- Naive Bayes is a **generative model** because it's modeling the joint distribution over the features $X$ and labels $y$.\n",
    "- It's weird to think of the features as random, but we're saying they come from those Gaussians above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in this course, we'll also study a **discriminative model**, which models $p(y\\mid x)$ rather than $p(x,y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General comments on Naive Bayes\n",
    "\n",
    "- Assumes that spammers generate e-mails by picking words at random. It means that sentences have no syntax and content. Is that a fair assumption? \n",
    "\n",
    "Note: [here](https://scikit-learn.org/stable/modules/naive_bayes.html) it says\n",
    "    \n",
    "> On the flip side, although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from `predict_proba` are not to be taken too seriously.\n",
    "\n",
    "\n",
    "The economist Milton Friedman has argued in a highly influential essay \n",
    "that an oversimplified model that you have enough data to estimate is better than a perfect one that you do not.\"\n",
    "\n",
    "> the best theories are the most oversimplified, provided their predictions are accurate, because they explain the most with the least. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's closely related to the perceptron algorithm or linear classifiers. \n",
    "    - When we take the logarithms, the products turn into summations. \n",
    "- Surprising accuracy \n",
    "- Scales great; learning a naive Bayes classifier is just a matter of counting how many times each attribute co-occurs with each class\n",
    "- A fast and robust way to learn the corresponding parameters\n",
    "- Provides a informative set of features from which to predict the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:571]",
   "language": "python",
   "name": "conda-env-571-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
