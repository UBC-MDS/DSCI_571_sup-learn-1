
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Lecture 7: Class demo &#8212; DSCI 571 Supervised Learning I</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/002-regressors-Varada-lectures/class_demos/demo_07-naive-Bayes';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Lectures 8: Class demo" href="demo_08-logistic-regression.html" />
    <link rel="prev" title="Lectures 6: Class demo" href="demo_06-hyperparameter-optimization.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/mds-hex-sticker.png" class="logo__image only-light" alt="DSCI 571 Supervised Learning I - Home"/>
    <script>document.write(`<img src="../../../_static/mds-hex-sticker.png" class="logo__image only-dark" alt="DSCI 571 Supervised Learning I - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Course Information</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../learning_objectives.html">Course Learning Objectives</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notes/00_motivation-course-information.html">Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/01_terminology-baselines-decision-trees.html">Lecture 1: Terminology, Baselines, Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/02_ml-fundamentals.html">Lecture 2: Machine Learning Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/03_kNNs-SVM-RBF.html">Lecture 3: <span class="math notranslate nohighlight">\(k\)</span>-Nearest Neighbours and SVM RBFs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/04_preprocessing-pipelines-column-transformer.html">Lecture 4: Preprocessing, <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> Pipeline, <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> ColumnTrasnsformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/05_more-preprocessing-text-feats.html">Lecture 5: More preprocessing, text features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/06_hyperparameter-optimization.html">Lecture 6: Hyperparameter Optimization and Optimization Bias</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/07_naive-Bayes.html">Lecture 7: Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/08_linear-models.html">Lecture 8: Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/appendixA_multiclass-strategies.html">Appendix A: Multi-class, meta-strategies</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Class Demos</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="demo_02-ml-fundamentals.html">Lecture 2: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo_03-kNNs-SVMs.html">Lecture 3: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo_04-preprocessing.html">Lecture 5: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo_05-text-features.html">Lectures 5: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo_06-hyperparameter-optimization.html">Lectures 6: Class demo</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lecture 7: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo_08-logistic-regression.html">Lectures 8: Class demo</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section slides</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../001-classifiers-Prajeet-lectures/README.html">Section 101 Classifiers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-01.html">Lecture 1</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-02.html">Lecture 2</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-03.html">Lecture 3</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-04.html">Lecture 4</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-05.html">Lecture 5</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-06.html">Lecture 6</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-07.html">Lecture 7</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-08.html">Lecture 8</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../README.html">Section 102 Regressors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-01.html">Lecture 1</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-02.html">Lecture 2</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-03.html">Lecture 3</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-04.html">Lecture 4</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-05.html">Lecture 5</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-06.html">Lecture 6</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-07.html">Lecture 7</a></li>
<li class="toctree-l2"><a class="reference external" href="https://pages.github.ubc.ca/mds-2024-25/DSCI_571-002-slides/lecture-08.html">Lecture 8</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Attribution</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../attribution.html">Attributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../LICENSE.html">LICENSE</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/UBC-MDS/DSCI_571_sup-learn-1" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/lectures/002-regressors-Varada-lectures/class_demos/demo_07-naive-Bayes.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 7: Class demo</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spam-classification-example">Spam classification example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svc-classifier-for-spam-detection">SVC classifier for spam detection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sklearn-naive-bayes-classifier"><code class="docutils literal notranslate"><span class="pre">sklearn</span></code> naive Bayes classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-predict">Naive Bayes <code class="docutils literal notranslate"><span class="pre">predict</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-prior-probabilities">Computing prior probabilities</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-conditional-probabilities">Computing conditional probabilities</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probabilities-for-the-target-spam">Conditional probabilities for the target spam</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probabilities-for-the-target-ham">Conditional probabilities for the target ham</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-naive-bayes-predict">Summary of naive Bayes <code class="docutils literal notranslate"><span class="pre">predict</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-naive-bayes-predict">Summary naive Bayes <code class="docutils literal notranslate"><span class="pre">predict</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#break-5-min">Break (5 min)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-classifier-fit">Naive Bayes classifier <code class="docutils literal notranslate"><span class="pre">fit</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-probabilities">Prior probabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probabilities">Conditional probabilities</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplace-smoothing">Laplace smoothing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simplest-solution-laplace-smoothing">A simplest solution: Laplace smoothing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#alpha-hyperparameter-and-the-fundamental-tradeoff"><code class="docutils literal notranslate"><span class="pre">alpha</span></code> hyperparameter and the fundamental tradeoff</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-details-on-the-formulas">(Optional) Details on the formulas</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-with-continuous-features">Naive Bayes with continuous features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-and-final-remarks">Summary and final remarks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-comments-on-naive-bayes">General comments on naive Bayes</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-7-class-demo">
<h1>Lecture 7: Class demo<a class="headerlink" href="#lecture-7-class-demo" title="Link to this heading">#</a></h1>
<section id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">),</span> <span class="s2">&quot;code&quot;</span><span class="p">))</span>

<span class="kn">import</span> <span class="nn">IPython</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="kn">from</span> <span class="nn">plotting_functions</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">GridSearchCV</span><span class="p">,</span>
    <span class="n">cross_val_score</span><span class="p">,</span>
    <span class="n">cross_validate</span><span class="p">,</span>
    <span class="n">train_test_split</span><span class="p">,</span>
<span class="p">)</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">BernoulliNB</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">,</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_colwidth&quot;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">),</span> <span class="s2">&quot;data/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="spam-classification-example">
<h2>Spam classification example<a class="headerlink" href="#spam-classification-example" title="Link to this heading">#</a></h2>
<section id="svc-classifier-for-spam-detection">
<h3>SVC classifier for spam detection<a class="headerlink" href="#svc-classifier-for-spam-detection" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Before discussing how it works, let’s try it out with sklearn.</p></li>
<li><p>Let’s first try SVC classifier on <a class="reference external" href="https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset">the SMS Spam Collection Dataset</a>. (This is what you did in the lab last week.)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sms_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_DIR</span> <span class="o">+</span> <span class="s2">&quot;spam.csv&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;latin-1&quot;</span><span class="p">)</span>
<span class="n">sms_df</span> <span class="o">=</span> <span class="n">sms_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;Unnamed: 2&quot;</span><span class="p">,</span> <span class="s2">&quot;Unnamed: 3&quot;</span><span class="p">,</span> <span class="s2">&quot;Unnamed: 4&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sms_df</span> <span class="o">=</span> <span class="n">sms_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;v1&quot;</span><span class="p">:</span> <span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="s2">&quot;v2&quot;</span><span class="p">:</span> <span class="s2">&quot;sms&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">sms_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;sms&quot;</span><span class="p">],</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;sms&quot;</span><span class="p">],</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>target</th>
      <th>sms</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>385</th>
      <td>ham</td>
      <td>It took Mr owl 3 licks</td>
    </tr>
    <tr>
      <th>4003</th>
      <td>ham</td>
      <td>Well there's a pattern emerging of my friends telling me to drive up and come smoke with them and then telling me that I'm a weed fiend/make them smoke too much/impede their doing other things so ...</td>
    </tr>
    <tr>
      <th>1283</th>
      <td>ham</td>
      <td>Yes i thought so. Thanks.</td>
    </tr>
    <tr>
      <th>2327</th>
      <td>spam</td>
      <td>URGENT! Your mobile number *************** WON a å£2000 Bonus Caller prize on 10/06/03! This is the 2nd attempt to reach you! Call 09066368753 ASAP! Box 97N7QP, 150ppm</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>ham</td>
      <td>Aiyah sorry lor... I watch tv watch until i forgot 2 check my phone.</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">pipe_svc</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">CountVectorizer</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">SVC</span><span class="p">())</span>
<span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;SVC&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">pipe_svc</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SVC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fit_time</th>
      <td>0.416 (+/- 0.007)</td>
    </tr>
    <tr>
      <th>score_time</th>
      <td>0.103 (+/- 0.002)</td>
    </tr>
    <tr>
      <th>test_score</th>
      <td>0.979 (+/- 0.004)</td>
    </tr>
    <tr>
      <th>train_score</th>
      <td>0.996 (+/- 0.001)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="sklearn-naive-bayes-classifier">
<h3><code class="docutils literal notranslate"><span class="pre">sklearn</span></code> naive Bayes classifier<a class="headerlink" href="#sklearn-naive-bayes-classifier" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Let’s try Naive Bayes on this problem.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span><span class="p">,</span> <span class="n">BernoulliNB</span>

<span class="n">pipe_nb</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">CountVectorizer</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">BernoulliNB</span><span class="p">())</span>
<span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;Naive Bayes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">pipe_nb</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SVC</th>
      <th>Naive Bayes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fit_time</th>
      <td>0.416 (+/- 0.007)</td>
      <td>0.029 (+/- 0.000)</td>
    </tr>
    <tr>
      <th>score_time</th>
      <td>0.103 (+/- 0.002)</td>
      <td>0.006 (+/- 0.000)</td>
    </tr>
    <tr>
      <th>test_score</th>
      <td>0.979 (+/- 0.004)</td>
      <td>0.974 (+/- 0.004)</td>
    </tr>
    <tr>
      <th>train_score</th>
      <td>0.996 (+/- 0.001)</td>
      <td>0.987 (+/- 0.001)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>The validation scores are very similar.</p></li>
<li><p>Much faster than the SVC classifier!!</p></li>
</ul>
<p>Now let’s try to understand how <code class="docutils literal notranslate"><span class="pre">predict</span></code> and <code class="docutils literal notranslate"><span class="pre">fit</span></code> work for this model. Let’s bring back the toy dataset from before and encode it with BOW representation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_toy</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Lol you are always so convincing. I&#39;m going to give you a free advice. It&#39;s urgent.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Block 2 has interesting courses.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Block 2 has been great so far.&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">y_toy</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;spam&quot;</span><span class="p">,</span> <span class="s2">&quot;ham&quot;</span><span class="p">,</span> <span class="s2">&quot;ham&quot;</span><span class="p">,</span> <span class="s2">&quot;spam&quot;</span><span class="p">,</span> <span class="s2">&quot;spam&quot;</span><span class="p">,</span> <span class="s2">&quot;ham&quot;</span><span class="p">]</span>
<span class="n">toy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;sms&quot;</span><span class="p">:</span><span class="n">X_toy</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span><span class="p">:</span><span class="n">y_toy</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>For simplicity, let’s use <code class="docutils literal notranslate"><span class="pre">CountVectorizer</span></code> with <code class="docutils literal notranslate"><span class="pre">binary=True</span></code>, i.e., assume presence or absence of words instead of counts and only consider the top 4 features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vec</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_toy_vec</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_toy</span><span class="p">,</span> <span class="n">y_toy</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">toy_bow_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">X_toy_vec</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vec</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">X_toy</span>
<span class="p">)</span>
<span class="n">toy_bow_df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_toy</span>
<span class="n">toy_bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>block</th>
      <th>free</th>
      <th>prize</th>
      <th>urgent</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Lol you are always so convincing. I'm going to give you a free advice. It's urgent.</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>Block 2 has interesting courses.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Block 2 has been great so far.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>ham</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s train a Bernoulli Naive Bayes model on this toy data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_toy_vec</span><span class="p">,</span> <span class="n">y_toy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>BernoulliNB</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.BernoulliNB.html">?<span>Documentation for BernoulliNB</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted"><pre>BernoulliNB()</pre></div> </div></div></div></div></div></div>
</div>
</section>
<section id="naive-bayes-predict">
<h3>Naive Bayes <code class="docutils literal notranslate"><span class="pre">predict</span></code><a class="headerlink" href="#naive-bayes-predict" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Given new messages, we want to predict whether they are spam or ham.</p></li>
<li><p>Example: Predict whether the following message is spam or ham.</p></li>
</ul>
<blockquote>
<div><p>“URGENT! Free!!”</p>
</div></blockquote>
<p>Remember the two simplifying assumptions of naive Bayes?</p>
<p><strong>BOW representaion</strong>: First, let’s get BOW representation of the message.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deploy_test</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;URGENT! Free!!&quot;</span><span class="p">,</span> <span class="s2">&quot;Let&#39;s enjoy the last week of block 2!&quot;</span><span class="p">]</span>
<span class="n">deploy_bow</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">deploy_test</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">bow_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">deploy_bow</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">vec</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">deploy_test</span>
<span class="p">)</span>
<span class="n">bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>block</th>
      <th>free</th>
      <th>prize</th>
      <th>urgent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT! Free!!</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Let's enjoy the last week of block 2!</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s predict with the Bernoulli Naive Bayes model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">deploy_bow</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;spam&#39;, &#39;ham&#39;], dtype=&#39;&lt;U4&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">deploy_bow</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.30769231, 0.69230769],
       [0.93103448, 0.06896552]])
</pre></div>
</div>
</div>
</div>
<p><br><br><br><br></p>
<p>What’s happening under the hood? To predict the correct class, assuming <strong>conditional independence</strong>, naive Bayes estimates some scores which are proportional to the following probabilities and picks the target with higher score.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(\text{spam} \mid \text{block} = 0, \text{free} = 1, \text{prize} = 0, \text{urgent=1}) \propto  P(\text{block} = 0, \text{free} = 1, \text{prize} = 0, \text{urgent=1} \mid \text{spam}) \times P(spam)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{ham} \mid  \text{block} = 0, \text{free} = 1, \text{prize} = 0, \text{urgent=1}) \propto  P(\text{block} = 0, \text{free} = 1, \text{prize} = 0, \text{urgent=1} \mid \text{spam}) \times P(ham)\)</span></p></li>
</ul>
<p>For each target, we need to calculate two probabilities:</p>
<ul class="simple">
<li><p><strong>Prior probabilities</strong>: <span class="math notranslate nohighlight">\(P(\text{target})\)</span></p></li>
<li><p><strong>Conditional probabilities</strong>: <span class="math notranslate nohighlight">\(P(\text{block} = 0, \text{free} = 1, \text{prize} = 0, \text{urgent=1} \mid \text{target})\)</span></p></li>
</ul>
<section id="computing-prior-probabilities">
<h4>Computing prior probabilities<a class="headerlink" href="#computing-prior-probabilities" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Prior probability: what’s the proportion of the target class occurs in our training dataset?</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(P(\text{spam}) = 3/6\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{ham}) = 3/6\)</span></p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">toy_bow_df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>target
spam    3
ham     3
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
</section>
<section id="computing-conditional-probabilities">
<h4>Computing conditional probabilities<a class="headerlink" href="#computing-conditional-probabilities" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Assumption: <strong>Features are independent, conditioned on the target</strong>.</p>
<ul>
<li><p>Example: In our spam classification example, <strong>once you know that a message is spam</strong>, the probability that the word “urgent” appears is independent of whether “free” also appeared.</p></li>
<li><p>So if you know that a message is spam, knowing whether the word “urgent” occurs gives no additional information about whether “free” also appears.</p></li>
</ul>
</li>
<li><p>We can write this mathematically as</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation}
\begin{split}
&amp; P(\text{block} = 0, \text{free} = 1, \text{prize} = 0, \text{urgent} = 1 \mid \text{spam}) \\
&amp;\approx P(\text{block} = 0 \mid \text{spam}) \times P(\text{free} = 1 \mid \text{spam}) \times P(\text{prize} = 0 \mid \text{spam}) \times P(\text{urgent} = 1 \mid \text{spam})\\\\
&amp; P(\text{block} = 0, \text{free} = 1, \text{prize} = 0, \text{urgent} = 1 \mid \text{ham}) \\
&amp;\approx P(\text{block} = 0 \mid \text{ham}) \times P(\text{free} = 1 \mid \text{ham}) \times P(\text{prize} = 0 \mid \text{ham}) \times P(\text{urgent} = 1 \mid \text{ham})
\end{split}
\end{equation}\end{split}\]</div>
<p>We can calculate these based on the frequencies of these words in our training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spam_toy_df</span> <span class="o">=</span> <span class="n">toy_df</span><span class="p">[</span><span class="n">toy_df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;spam&#39;</span><span class="p">]</span>
<span class="n">ham_toy_df</span> <span class="o">=</span> <span class="n">toy_df</span><span class="p">[</span><span class="n">toy_df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;ham&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_spam_ham_word_freq</span><span class="p">(</span><span class="n">spam_toy_df</span><span class="p">[</span><span class="s1">&#39;sms&#39;</span><span class="p">],</span> <span class="n">ham_toy_df</span><span class="p">[</span><span class="s1">&#39;sms&#39;</span><span class="p">])</span> <span class="c1"># custom function defined in code/plotting_functions.oy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/kvarada/MDS/2024-25/571/DSCI_571_sup-learn-1/lectures/002-regressors-Varada-lectures/../code/plotting_functions.py:99: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax[0].set_xticklabels(labels=spam_words, rotation=45)
/Users/kvarada/MDS/2024-25/571/DSCI_571_sup-learn-1/lectures/002-regressors-Varada-lectures/../code/plotting_functions.py:108: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax[1].set_xticklabels(labels=ham_words, rotation=45)
</pre></div>
</div>
<img alt="../../../_images/d0d0936f6fed8351f33a21baaa4a0d7d2bce50ae575a7d63c695b1851a225787.png" src="../../../_images/d0d0936f6fed8351f33a21baaa4a0d7d2bce50ae575a7d63c695b1851a225787.png" />
</div>
</div>
<p>So in this toy example, for each target, we need the following conditional probabilities for prediction.</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(P(\text{block} = 0 \mid \text{target})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{free} = 1 \mid \text{target})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{target})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{urgent} = 1 \mid \text{target})\)</span>
use our training data to estimate these probabilities.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">toy_bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>block</th>
      <th>free</th>
      <th>prize</th>
      <th>urgent</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Lol you are always so convincing. I'm going to give you a free advice. It's urgent.</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>Block 2 has interesting courses.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Block 2 has been great so far.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>ham</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="conditional-probabilities-for-the-target-spam">
<h4>Conditional probabilities for the target spam<a class="headerlink" href="#conditional-probabilities-for-the-target-spam" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>What is <span class="math notranslate nohighlight">\(P(\text{block} = 0 \mid \text{spam})\)</span>?</p>
<ul>
<li><p>Given target is spam, how often “block” = 0? <span class="math notranslate nohighlight">\(3/3\)</span></p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(P(\text{free} = 1 \mid \text{spam}) = 2/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{spam}) = 1/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{urgent} = 1 \mid \text{spam}) = 2/3\)</span></p></li>
</ul>
<p>So using naive Bayes, <span class="math notranslate nohighlight">\(P(\text{spam} \mid \text{message})\)</span> is proportional to</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation}
\begin{split}
P(\text{spam} \mid \text{message}) &amp;\propto P(\text{block} = 0, \text{free} = 1, \text{prize} = 0, \text{urgent} = 1 \mid \text{spam}) \times P(\text{spam})\\
&amp;\propto P(\text{block} = 0 \mid \text{spam}) \times P(\text{free} = 1 \mid \text{spam}) \\
&amp; \times P(\text{prize} = 0 \mid \text{spam}) \times P(\text{urgent} = 1 \mid \text{spam}) \times P(\text{spam})\\
&amp;\propto 3/3 \times 2/3 \times 1/3 \times 2/3 \times 3/6\\
\end{split}
\end{equation}\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spam_prior</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">6</span>
<span class="n">block0_spam</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">free1_spam</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">prize0_spam</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">urgent1_spam</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">spam_estimate</span> <span class="o">=</span> <span class="n">spam_prior</span> <span class="o">*</span> <span class="n">block0_spam</span> <span class="o">*</span> <span class="n">free1_spam</span> <span class="o">*</span> <span class="n">prize0_spam</span> <span class="o">*</span> <span class="n">urgent1_spam</span>
<span class="n">spam_estimate</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.07407407407407407
</pre></div>
</div>
</div>
</div>
</section>
<section id="conditional-probabilities-for-the-target-ham">
<h4>Conditional probabilities for the target ham<a class="headerlink" href="#conditional-probabilities-for-the-target-ham" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>What is <span class="math notranslate nohighlight">\(P(\text{block} = 0 \mid \text{ham})\)</span>?</p>
<ul>
<li><p>Given target is ham, how often “block” = 0? <span class="math notranslate nohighlight">\(1/3\)</span></p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(P(\text{free} = 1 \mid \text{ham}) = 1/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{prize} = 0 \mid \text{ham}) = 3/3\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{urgent} = 1 \mid \text{ham}) = 1/3\)</span></p></li>
</ul>
<p>So using naive Bayes, <span class="math notranslate nohighlight">\(P(\text{ham} \mid \text{message})\)</span> is proportional to
$<span class="math notranslate nohighlight">\(\begin{equation}
\begin{split}
P(\text{ham} \mid \text{message}) &amp;\propto P(\text{block} = 0, \text{free} = 1, \text{prize} = 0, \text{urgent} = 1 \mid \text{ham}) \times P(\text{ham})\\
&amp;\propto P(\text{block} = 0 \mid \text{ham}) \times P(\text{free} = 1 \mid \text{ham}) \\
&amp; \times P(\text{prize} = 0 \mid \text{ham}) \times P(\text{urgent} = 1 \mid \text{ham}) \times P(\text{ham})\\
&amp;\propto 1/3 \times 1/3 \times 3/3 \times 1/3 \times 3/6\\
\end{split}
\end{equation}\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ham_prior</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">6</span>
<span class="n">block0_ham</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">free1_ham</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">prize0_ham</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">urgent1_ham</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">ham_estimate</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ham_prior</span>
    <span class="o">*</span> <span class="n">block0_ham</span>
    <span class="o">*</span> <span class="n">free1_ham</span>
    <span class="o">*</span> <span class="n">prize0_ham</span>
    <span class="o">*</span> <span class="n">urgent1_ham</span>
<span class="p">)</span>
<span class="n">ham_estimate</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.018518518518518517
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;spam estimate: &#39;</span><span class="p">,</span> <span class="n">spam_estimate</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;ham estimate: &#39;</span><span class="p">,</span> <span class="n">ham_estimate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>spam estimate:  0.07407407407407407
ham estimate:  0.018518518518518517
</pre></div>
</div>
</div>
</div>
<p>Since <span class="math notranslate nohighlight">\(P(spam \mid message)\)</span> is proportional to a bigger number, we pick “spam” as the label.</p>
<ul class="simple">
<li><p>Note that these estimates are not well-defined probabilities, as we ignored the denominator when calculating these estimates.</p></li>
<li><p>Let’s normalize these estimates so that they sum to 1.0</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normalizer</span> <span class="o">=</span> <span class="n">spam_estimate</span> <span class="o">+</span> <span class="n">ham_estimate</span>
<span class="n">spam_prob_score</span> <span class="o">=</span> <span class="n">spam_estimate</span> <span class="o">/</span> <span class="n">normalizer</span>
<span class="n">ham_prob_score</span> <span class="o">=</span> <span class="n">ham_estimate</span> <span class="o">/</span> <span class="n">normalizer</span>
<span class="p">[</span><span class="n">ham_prob_score</span><span class="p">,</span> <span class="n">spam_prob_score</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.2, 0.8]
</pre></div>
</div>
</div>
</div>
<p>Let’s examine whether we get the same numbers with <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">BernoulliNB</span></code>.</p>
<ul class="simple">
<li><p>We are using <code class="docutils literal notranslate"><span class="pre">BernoulliNB</span></code> because our features are binary.</p></li>
</ul>
<p><br><br></p>
</section>
</section>
<section id="summary-of-naive-bayes-predict">
<h3>Summary of naive Bayes <code class="docutils literal notranslate"><span class="pre">predict</span></code><a class="headerlink" href="#summary-of-naive-bayes-predict" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Use Bayes rule to calculate the conditional probability of each target given the message.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ P(\text{target} \mid \text{message}) = \frac{P(\text{message} \mid \text{target}) \times P(\text{target})}{P(\text{message})} \]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(\text{message})\)</span>: marginal probability that a message has the given set of words</p>
<ul>
<li><p>Hard to calculate but can be ignored in our scenario.</p></li>
</ul>
</li>
</ul>
<div class="math notranslate nohighlight">
\[ P(\text{target} \mid \text{message}) \propto P(\text{message} \mid\text{target}) \times P(\text{target}) =  P(w_1, w_2, \dots, w_d \mid \text{target}) \times P(\text{target})\]</div>
<ul>
<li><p>We need the following terms:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(P(\text{target})\)</span>: marginal probability that a message has the class target</p></li>
<li><p><span class="math notranslate nohighlight">\(P(\text{message}\mid\text{target})\)</span>: conditional probability that message has words <span class="math notranslate nohighlight">\(w_1, w_2, \dots, w_d\)</span>, given that it is of the given target.</p>
<ul class="simple">
<li><p>Hard to calculate but we need it. We would require huge numbers of parameters and impossibly large training sets.</p></li>
<li><p>Naive assumption that features are independent of each other conditioned on the target.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(\text{message} \mid \text{target}) = P(w_1, w_2, . . . , w_d \mid \text{target}) \approx \prod_{i=1}^{d}P(w_i \mid \text{target})\]</div>
</li>
</ul>
</li>
</ul>
</section>
<section id="summary-naive-bayes-predict">
<h3>Summary naive Bayes <code class="docutils literal notranslate"><span class="pre">predict</span></code><a class="headerlink" href="#summary-naive-bayes-predict" title="Link to this heading">#</a></h3>
<p>Using naive Bayes assumption, estimate scores that are proportional to the following probabilities.</p>
<div class="math notranslate nohighlight">
\[ P(\text{target} \mid \text{message}) \propto P(\text{target}) \times  \prod_{i=1}^{d}P(w_i \mid \text{target})\]</div>
<ul class="simple">
<li><p>Predict the target where <span class="math notranslate nohighlight">\(P(\text{target} \mid \text{message})\)</span> is proportional to a bigger value.</p></li>
</ul>
</section>
</section>
<section id="break-5-min">
<h2>Break (5 min)<a class="headerlink" href="#break-5-min" title="Link to this heading">#</a></h2>
<p><img alt="" src="../../../_images/eva-coffee.png" /></p>
<section id="naive-bayes-classifier-fit">
<h3>Naive Bayes classifier <code class="docutils literal notranslate"><span class="pre">fit</span></code><a class="headerlink" href="#naive-bayes-classifier-fit" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Counting and estimating probabilities.</p></li>
<li><p>Estimate prior probabilities and conditional probabilities for each feature given each class.</p></li>
</ul>
</section>
<section id="prior-probabilities">
<h3>Prior probabilities<a class="headerlink" href="#prior-probabilities" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>P(target) <span class="math notranslate nohighlight">\(\rightarrow\)</span> how often target <span class="math notranslate nohighlight">\(c\)</span> occurs in our dataset in comparison with all other targets.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(c) = \frac{N_c}{N}\]</div>
<p>where,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N_c\)</span> is the number of examples with target <span class="math notranslate nohighlight">\(c\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(N\)</span> is total number of examples</p></li>
</ul>
</section>
<section id="conditional-probabilities">
<h3>Conditional probabilities<a class="headerlink" href="#conditional-probabilities" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Above, we only calculated conditional probabilities which were required for estimating probability score for class given given message.</p></li>
<li><p>Naive Bayes calculates all conditional probabilities for each feature given each class in advance during <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p></li>
<li><p>Then during <code class="docutils literal notranslate"><span class="pre">predict</span></code> it just multiplies the appropriate probabilities.</p></li>
</ul>
<p>In case of Bernoulli naive Bayes with binary classification, for each feature <span class="math notranslate nohighlight">\(w\)</span> and target <span class="math notranslate nohighlight">\(c\)</span>, it calculates four probabilities:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(w = 1 \mid c = 0) \rightarrow\)</span> Probability that the word is present given target 0.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(w = 0 \mid c = 0) \rightarrow\)</span> Probability that the word is absent given target 0.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(w = 1 \mid c = 1) \rightarrow\)</span> Probability that the word is present given target 1.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(w = 0 \mid c = 1) \rightarrow\)</span> Probability that the word is absent given target 1.</p></li>
</ul>
<p>But <span class="math notranslate nohighlight">\(P(w = 0 \mid c = 0) = 1 - P(w = 1 \mid c = 0)\)</span>
And <span class="math notranslate nohighlight">\(P(w = 0 \mid c = 1) = 1 - P(w = 1 \mid c = 1)\)</span></p>
<p>So in reality we just need to calculate two probabilities for each word.</p>
<p>We calculate these probabilities by counting word and target occurrences in the training data. For example,
$<span class="math notranslate nohighlight">\( P(w = 1\mid c = 1) = \frac{Count(w = 1, c = 1)}{Count(c = 1)}\)</span>$</p>
<ul class="simple">
<li><p>This is called <em>maximum likelihood estimation</em>.</p></li>
<li><p>It stores these probabilities, which will be later used during predict time.</p></li>
</ul>
<p><br><br><br><br></p>
</section>
</section>
<section id="laplace-smoothing">
<h2>Laplace smoothing<a class="headerlink" href="#laplace-smoothing" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">toy_bow_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>block</th>
      <th>free</th>
      <th>prize</th>
      <th>urgent</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>URGENT!! As a valued network customer you have been selected to receive a £900 prize reward!</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Lol you are always so convincing. I'm going to give you a free advice. It's urgent.</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>Block 2 has interesting courses.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>URGENT! You have won a 1 week FREE membership in our £100000 prize Jackpot!</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free!</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>Block 2 has been great so far.</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>ham</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>What will happen if you want to predict for:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_ex</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;urgent free block&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transformed</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_ex</span><span class="p">)</span>
<span class="n">transformed</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1, 1, 0, 1]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spam_prior</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">6</span>
<span class="n">block1_spam</span> <span class="o">=</span> <span class="mi">0</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">free1_spam</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">prize0_spam</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">urgent1_spam</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">3</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spam_prior</span> <span class="o">*</span> <span class="n">block1_spam</span> <span class="o">*</span> <span class="n">free1_spam</span> <span class="o">*</span> <span class="n">prize0_spam</span> <span class="o">*</span> <span class="n">urgent1_spam</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Although all the other words are yelling SPAM! SPAM! SPAM!, since we do not have any example where the word “block” occurs with spam, we get a zero probability.</p></li>
</ul>
<p><img alt="" src="../../../_images/eva-qm.png" /></p>
<ul class="simple">
<li><p>Naive Bayes naively multiplies all the feature likelihoods together, and if any of the terms is zero, it’s going to void all other evidence and the probability of the class is going to be zero.</p></li>
<li><p>Sounds worrisome!</p></li>
<li><p>We have limited data and if we do not see a feature occurring with a class, it doesn’t mean it would never occur with that class.</p></li>
<li><p>How can we tackle this and avoid obliterating all other probabilities because of one zero in the product?</p></li>
</ul>
<section id="a-simplest-solution-laplace-smoothing">
<h3>A simplest solution: Laplace smoothing<a class="headerlink" href="#a-simplest-solution-laplace-smoothing" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The simplest way to avoid zero probabilities is to add one to the counts when we calculate conditional probabilities.</p></li>
<li><p>For example, a smoothed probability of<br />
$<span class="math notranslate nohighlight">\( P(\text{block} = 1 \mid \text{spam}) = = \frac{\text{\# documents where block occurs with spam} + 1 }{\text{how often spam occurs} + \text{\# number of possible word values}}\)</span>$</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ P(\text{block} = 1 \mid \text{spam}) = \frac{0 + 1}{3+2}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spam_prior</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">/</span> <span class="mi">6</span>
<span class="n">block1_spam_sm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">free1_spam_sm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">prize0_spam_sm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">urgent1_spam_sm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spam_prior</span> <span class="o">*</span> <span class="n">block1_spam_sm</span> <span class="o">*</span> <span class="n">free1_spam_sm</span> <span class="o">*</span> <span class="n">prize0_spam_sm</span> <span class="o">*</span> <span class="n">urgent1_spam_sm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0144
</pre></div>
</div>
</div>
</div>
<p>All the counts that used to be zero will now have a count of 1</p>
<p>We can generalize to adding <span class="math notranslate nohighlight">\(\alpha\)</span> instead of 1. So for each feature <span class="math notranslate nohighlight">\(w_i\)</span> in the Bernoulli model, smoothing adds <span class="math notranslate nohighlight">\(\alpha\)</span> “pseudo-counts” to both cases:</p>
<ul class="simple">
<li><p>When <span class="math notranslate nohighlight">\(w_i = 1\)</span> (word present).</p></li>
<li><p>When <span class="math notranslate nohighlight">\(w_i = 0\)</span> (word absent).</p></li>
</ul>
<p>If <span class="math notranslate nohighlight">\(\alpha = 1\)</span> (Laplace smoothing), it’s like adding 1 pseudo-example where <span class="math notranslate nohighlight">\(w_i = 1\)</span> and another 1 pseudo-example where <span class="math notranslate nohighlight">\(w_i = 0\)</span>, for each word and class.</p>
<p>In summary, smoothing acts as if each individual feature has been observed slightly more times than it actually was—this prevents probabilities from becoming 0</p>
<ul class="simple">
<li><p>In <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> we control it using hyperparameter <code class="docutils literal notranslate"><span class="pre">alpha</span></code> (by default <code class="docutils literal notranslate"><span class="pre">alpha=1.0</span></code>).</p></li>
<li><p>Check out sklearn’s documentation on <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html">BernoulliNB</a></p></li>
</ul>
<p>Let’s try this out on the example above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_ex</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;urgent free block&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transformed</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1, 1, 0, 1]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We are now getting more sensible probabilities.   </span>
<span class="n">nb_sm</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">nb_sm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_toy_vec</span><span class="p">,</span> <span class="n">y_toy</span><span class="p">)</span>
<span class="n">nb_sm</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">transformed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.72727273, 0.27272727]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nb_sm</span><span class="o">.</span><span class="n">classes_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;ham&#39;, &#39;spam&#39;], dtype=&#39;&lt;U4&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="alpha-hyperparameter-and-the-fundamental-tradeoff">
<h3><code class="docutils literal notranslate"><span class="pre">alpha</span></code> hyperparameter and the fundamental tradeoff<a class="headerlink" href="#alpha-hyperparameter-and-the-fundamental-tradeoff" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>High alpha <span class="math notranslate nohighlight">\(\rightarrow\)</span> underfitting</p>
<ul>
<li><p>means we are adding large counts to everything and so we are diluting the data</p></li>
</ul>
</li>
<li><p>Low alpha <span class="math notranslate nohighlight">\(\rightarrow\)</span> overfitting</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;mean_train_score&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;mean_cv_score&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;std_cv_score&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;std_train_score&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="p">}</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;bernoullinb__alpha&quot;</span><span class="p">:</span> <span class="mf">10.0</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">)}</span>

<span class="n">pipe_nb</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">CountVectorizer</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">BernoulliNB</span><span class="p">())</span>
<span class="n">search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe_nb</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_scores</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">]</span>
<span class="n">train_scores</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_train_score&quot;</span><span class="p">]</span>
<span class="n">alpha_vals</span> <span class="o">=</span> <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;bernoullinb__alpha&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">semilogx</span><span class="p">(</span><span class="n">alpha_vals</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogx</span><span class="p">(</span><span class="n">alpha_vals</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;cv&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;laplace smoothing (alpha)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/c6ad114c8d81bdf3795f5a9d8a51608a179b13c8737774a2a671f79eb3fa1aa8.png" src="../../../_images/c6ad114c8d81bdf3795f5a9d8a51608a179b13c8737774a2a671f79eb3fa1aa8.png" />
</div>
</div>
</section>
<section id="optional-details-on-the-formulas">
<h3>(Optional) Details on the formulas<a class="headerlink" href="#optional-details-on-the-formulas" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>In case of <code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code>, the conditional probabilities will change with the following formula.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ P(w \mid c) = \frac{Count(w, c) + 1 }{Count(c) + \mid vocabulary \mid}\]</div>
<ul class="simple">
<li><p>In case of Bernoulli naive Bayes, when you calculate conditional probabilities with Laplace smoothing, the formula is slightly different:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ P(w \mid c) = \frac{Count(w, c) + 1 }{Count(c) + 2 }\]</div>
<ul class="simple">
<li><p>So instead of the <span class="math notranslate nohighlight">\(\mid vocabulary \mid\)</span> we just add 2. See the sklearn code <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/0d378913b/sklearn/naive_bayes.py#L1031">here</a> and <a class="reference external" href="https://stackoverflow.com/questions/40448784/laplace-smoothing-for-bernoulli-model-for-naive-bayes-classifier">this Stack overflow post</a> for explanation.</p></li>
</ul>
<p>Note that when we estimated probabilities in our toy example (e.g., <span class="math notranslate nohighlight">\(P(\text{word} \mid spam)\)</span>), we happened to have each feature value as either 0 or 1, i.e., just the existence of a word in the document’s bag of words. We computed <span class="math notranslate nohighlight">\(P(\text{word} \mid spam)\)</span> as a fraction of times the word appears among all words in all messages of the spam class. If we want to work with frequencies instead of existence, we first concatenate all documents with that class (e.g., spam class) into one big “class c” text. Then we use the frequency of the word (e.g., <em>urgent</em> below) in this concatenated document to give a (maximum likelihood) estimate of the probability:</p>
<div class="math notranslate nohighlight">
\[P(\text{urgent} \mid \text{spam}) = \frac{Count(\text{urgent}, \text{spam})}{\sum_{w \in vocabulary} Count(w, \text{spam})}\]</div>
<div class="math notranslate nohighlight">
\[P(\text{urgent} \mid \text{spam}) = \frac{\text{how often urgent occurs with spam}}{\text{total number of tokens (all occurrences of all words) in spam}}\]</div>
<p><br><br><br><br></p>
</section>
</section>
<section id="naive-bayes-with-continuous-features">
<h2>Naive Bayes with continuous features<a class="headerlink" href="#naive-bayes-with-continuous-features" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>We can use Gaussian Naive Bayes if you have continuous features. (<a class="reference external" href="https://www.youtube.com/watch?v=H3EjCKtlVog">Watch this</a>).</p></li>
<li><p>Here is the general idea of Gaussian naive Bayes:</p>
<ul>
<li><p>Assume each feature is normally distributed.</p></li>
<li><p>Calculate the mean (<span class="math notranslate nohighlight">\(\mu_k\)</span>) and standard deviation (<span class="math notranslate nohighlight">\(\sigma_k\)</span>) for each feature for each class.</p></li>
<li><p>Use the following equation to calculate the likelihood of observing feature value <span class="math notranslate nohighlight">\(v\)</span> in class <span class="math notranslate nohighlight">\(C_k\)</span></p></li>
</ul>
</li>
</ul>
<p><img alt="" src="../../../_images/gaus_nb.png" /></p>
<!-- <center>
<img src='./img/gaus_nb.png' width="400">
</center>
 -->
<p>Source: <a class="reference external" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes">Wikipedia</a></p>
<p>Let’s work through a toy example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Weight (in grams)&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">105</span><span class="p">,</span> <span class="mi">103</span><span class="p">,</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">162</span><span class="p">,</span> <span class="mi">163</span><span class="p">,</span> <span class="mi">164</span><span class="p">],</span>
    <span class="s1">&#39;Sugar Content (in %)&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mf">10.5</span><span class="p">,</span> <span class="mf">10.2</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mf">19.5</span><span class="p">,</span> <span class="mf">18.8</span><span class="p">],</span>
    <span class="s1">&#39;Fruit&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Apple&#39;</span><span class="p">,</span> <span class="s1">&#39;Apple&#39;</span><span class="p">,</span> <span class="s1">&#39;Apple&#39;</span><span class="p">,</span> <span class="s1">&#39;Apple&#39;</span><span class="p">,</span> <span class="s1">&#39;Orange&#39;</span><span class="p">,</span> <span class="s1">&#39;Orange&#39;</span><span class="p">,</span> <span class="s1">&#39;Orange&#39;</span><span class="p">,</span> <span class="s1">&#39;Orange&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Weight (in grams)</th>
      <th>Sugar Content (in %)</th>
      <th>Fruit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>100</td>
      <td>10.0</td>
      <td>Apple</td>
    </tr>
    <tr>
      <th>1</th>
      <td>105</td>
      <td>11.0</td>
      <td>Apple</td>
    </tr>
    <tr>
      <th>2</th>
      <td>103</td>
      <td>10.5</td>
      <td>Apple</td>
    </tr>
    <tr>
      <th>3</th>
      <td>101</td>
      <td>10.2</td>
      <td>Apple</td>
    </tr>
    <tr>
      <th>4</th>
      <td>160</td>
      <td>18.0</td>
      <td>Orange</td>
    </tr>
    <tr>
      <th>5</th>
      <td>162</td>
      <td>19.0</td>
      <td>Orange</td>
    </tr>
    <tr>
      <th>6</th>
      <td>163</td>
      <td>19.5</td>
      <td>Orange</td>
    </tr>
    <tr>
      <th>7</th>
      <td>164</td>
      <td>18.8</td>
      <td>Orange</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_gaussians</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="c1"># custom-defined function in code/plotting_functions.py</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/8c95a8aba929f73c73d45d498218f124b059926282d8a622488b3b3700bef97f.png" src="../../../_images/8c95a8aba929f73c73d45d498218f124b059926282d8a622488b3b3700bef97f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Weight (in grams)</th>
      <th>Sugar Content (in %)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>8.000000</td>
      <td>8.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>132.250000</td>
      <td>14.625000</td>
    </tr>
    <tr>
      <th>std</th>
      <td>32.123645</td>
      <td>4.517506</td>
    </tr>
    <tr>
      <th>min</th>
      <td>100.000000</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>102.500000</td>
      <td>10.425000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>132.500000</td>
      <td>14.500000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>162.250000</td>
      <td>18.850000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>164.000000</td>
      <td>19.500000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_toy</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Fruit&#39;</span><span class="p">])</span>
<span class="n">y_toy</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Fruit&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s say we have a test fruit with a weight of 106 grams and a sugar content of 11% and we want to predict the class.
We’ll compute the likelihood of these values for both fruits using the Gaussian pdf:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gaussian_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">variance</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">variance</span><span class="p">))</span>

<span class="c1"># Compute conditional probabilities for the given observation</span>
<span class="n">observed_weight</span> <span class="o">=</span> <span class="mi">106</span>
<span class="n">observed_sugar_content</span> <span class="o">=</span> <span class="mi">11</span>

<span class="n">likelihoods</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">fruit</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Apple&#39;</span><span class="p">,</span> <span class="s1">&#39;Orange&#39;</span><span class="p">]:</span>
    <span class="n">likelihoods</span><span class="p">[</span><span class="n">fruit</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">observed_value</span> <span class="ow">in</span> <span class="p">[(</span><span class="s1">&#39;Weight (in grams)&#39;</span><span class="p">,</span> <span class="n">observed_weight</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Sugar Content (in %)&#39;</span><span class="p">,</span> <span class="n">observed_sugar_content</span><span class="p">)]:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Fruit&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">fruit</span><span class="p">][</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Fruit&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">fruit</span><span class="p">][</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
        <span class="n">likelihoods</span><span class="p">[</span><span class="n">fruit</span><span class="p">][</span><span class="n">feature</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">observed_value</span><span class="p">)]</span> <span class="o">=</span> <span class="n">gaussian_pdf</span><span class="p">(</span><span class="n">observed_value</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">)</span>
        
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">likelihoods</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Apple</th>
      <th>Orange</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Weight (in grams)=106</th>
      <td>0.043052</td>
      <td>6.345802e-237</td>
    </tr>
    <tr>
      <th>Sugar Content (in %)=11</th>
      <td>0.382788</td>
      <td>4.368922e-35</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><span class="math notranslate nohighlight">\(p(Apple \mid  \text{Weight (in grams) = 106, Sugar Content (in \%) = 11}) = \)</span>
<span class="math notranslate nohighlight">\( p(Apple) \times p(\text{Weight (in grams} = 106 \mid c = \text{Apple})  \times  p(\text{Sugar Content (in \%)} = 11 \mid c = \text{Apple})\)</span></p>
<p><span class="math notranslate nohighlight">\(p(Orange \mid  \text{Weight (in grams) = 106, Sugar Content (in \%) = 11}) = \)</span>
<span class="math notranslate nohighlight">\( p(Orange) \times p(\text{Weight (in grams} = 106 \mid c = \text{Orange})  \times  p(\text{Sugar Content (in \%)} = 11 \mid c = \text{Orange})\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_toy</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_toy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-2 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>GaussianNB</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.GaussianNB.html">?<span>Documentation for GaussianNB</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted"><pre>GaussianNB()</pre></div> </div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">var_</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">theta_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([[3.6875009, 0.1418759],
        [2.1875009, 0.2918759]]),
 array([[102.25 ,  10.425],
        [162.25 ,  18.825]]))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">class_prior_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.5, 0.5])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mf">106.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;Apple&#39;], dtype=&#39;&lt;U6&#39;)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Gaussian naive Bayes assumes normality</p>
<ul>
<li><p>If the features are not normally distributed transform the data to make them more normal</p></li>
<li><p>Scikit-learn provides the <code class="docutils literal notranslate"><span class="pre">PowerTransformer()</span></code> for this process</p></li>
<li><p>From the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer">docs</a>: “<em>…Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like.</em>”</p></li>
</ul>
</li>
</ul>
</section>
<section id="summary-and-final-remarks">
<h2>Summary and final remarks<a class="headerlink" href="#summary-and-final-remarks" title="Link to this heading">#</a></h2>
<section id="general-comments-on-naive-bayes">
<h3>General comments on naive Bayes<a class="headerlink" href="#general-comments-on-naive-bayes" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Family of probabilistic classifiers</p></li>
<li><p>GausianNB is used on very high dimensional numeric data</p></li>
<li><p>BernoulliNB and MultinomialNB are used for sparse data (e.g., text data).</p>
<ul>
<li><p>MultinomialNB usually performs better than BernoulliNB, especially when you are working with large documents.</p></li>
<li><p>Complexity hyperparameter: <code class="docutils literal notranslate"><span class="pre">alpha</span></code></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>A fast and robust way to learn the corresponding parameters</p></li>
<li><p>Training procedure is easy to understand</p></li>
<li><p>Surprising accuracy considering its simplicity</p></li>
<li><p>Scales great; learning a naive Bayes classifier is just a matter of counting how many times each attribute co-occurs with each class</p></li>
<li><p>To avoid underflow, all the calculations are done with log likelihoods.</p></li>
<li><p>Can be easily used for multi-class classification</p></li>
</ul>
<ul class="simple">
<li><p>It’s closely related to linear classifiers, which we’ll see in the next lecture.</p>
<ul>
<li><p>When we take the logarithms, the products turn into summations.</p></li>
</ul>
</li>
<li><p>Can provides a informative set of features from which to predict the class (next class)</p></li>
</ul>
<ul class="simple">
<li><p>Often provide generalization performance that is slightly worse</p></li>
<li><p>Assumes that spammers generate e-mails by picking words at random. It means that sentences have no syntax and content. Is that a fair assumption?</p>
<ul>
<li><p>oversimplification</p></li>
<li><p>sometimes the best theories are the most oversimplified 🤷🏻‍♀️</p></li>
</ul>
</li>
<li><p>Although naive Bayes is known as a decent classifier, it is known to be a <strong>bad estimator</strong>, so the probability outputs from <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> are not to be taken too seriously.</p></li>
</ul>
<p><img alt="" src="../../../_images/eva-seeyou.png" /></p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-571-py"
        },
        kernelOptions: {
            name: "conda-env-571-py",
            path: "./lectures/002-regressors-Varada-lectures/class_demos"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-571-py'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="demo_06-hyperparameter-optimization.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lectures 6: Class demo</p>
      </div>
    </a>
    <a class="right-next"
       href="demo_08-logistic-regression.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lectures 8: Class demo</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spam-classification-example">Spam classification example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svc-classifier-for-spam-detection">SVC classifier for spam detection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sklearn-naive-bayes-classifier"><code class="docutils literal notranslate"><span class="pre">sklearn</span></code> naive Bayes classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-predict">Naive Bayes <code class="docutils literal notranslate"><span class="pre">predict</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-prior-probabilities">Computing prior probabilities</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-conditional-probabilities">Computing conditional probabilities</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probabilities-for-the-target-spam">Conditional probabilities for the target spam</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probabilities-for-the-target-ham">Conditional probabilities for the target ham</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-naive-bayes-predict">Summary of naive Bayes <code class="docutils literal notranslate"><span class="pre">predict</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-naive-bayes-predict">Summary naive Bayes <code class="docutils literal notranslate"><span class="pre">predict</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#break-5-min">Break (5 min)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-classifier-fit">Naive Bayes classifier <code class="docutils literal notranslate"><span class="pre">fit</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-probabilities">Prior probabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probabilities">Conditional probabilities</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplace-smoothing">Laplace smoothing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simplest-solution-laplace-smoothing">A simplest solution: Laplace smoothing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#alpha-hyperparameter-and-the-fundamental-tradeoff"><code class="docutils literal notranslate"><span class="pre">alpha</span></code> hyperparameter and the fundamental tradeoff</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-details-on-the-formulas">(Optional) Details on the formulas</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-with-continuous-features">Naive Bayes with continuous features</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-and-final-remarks">Summary and final remarks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-comments-on-naive-bayes">General comments on naive Bayes</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Varada Kolhatkar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>